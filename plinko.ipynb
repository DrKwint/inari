{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
    "  ds_builder = tfds.builder('mnist')\n",
    "  ds_builder.download_and_prepare()\n",
    "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "  return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = jnp.reshape(x, [-1, 784])\n",
    "    x = nn.Dense(8)(x)\n",
    "    self.sow('intermediates', 'x1', x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(8)(x)\n",
    "    self.sow('intermediates', 'x2', x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(10)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "    labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(*, logits, labels):\n",
    "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "  }\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    net = Net()\n",
    "    params = net.init(rng, jnp.ones([1, 28, 28, 1]))['params']\n",
    "    tx = optax.adamw(learning_rate)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=net.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = Net().apply({'params': params}, batch['image'])\n",
    "        loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "  \"\"\"Train for a single epoch.\"\"\"\n",
    "  train_ds_size = len(train_ds['image'])\n",
    "  steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "  perms = jax.random.permutation(rng, train_ds_size)\n",
    "  perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "  batch_metrics = []\n",
    "  for perm in perms:\n",
    "    batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "    state, metrics = train_step(state, batch)\n",
    "    batch_metrics.append(metrics)\n",
    "\n",
    "  # compute mean of metrics across each batch in epoch.\n",
    "  batch_metrics_np = jax.device_get(batch_metrics)\n",
    "  epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]}\n",
    "\n",
    "  print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
    "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
    "\n",
    "  return state\n",
    "\n",
    "def forward_batch(state, batch_size, rng):\n",
    "  train_ds_size = len(train_ds['image'])\n",
    "  perms = jax.random.permutation(rng, train_ds_size)\n",
    "  perm = perms[:batch_size]  # skip incomplete batch\n",
    "  batch = {k: v[perm, ...] for k, v in train_ds.items()}\n",
    "  _, state = Net().apply({'params': state.params}, batch['image'], mutable=['intermediates'])\n",
    "  return state['intermediates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "  logits = Net().apply({'params': params}, batch['image'])\n",
    "  return compute_metrics(logits=logits, labels=batch['label'])\n",
    "\n",
    "def eval_model(params, test_ds):\n",
    "  metrics = eval_step(params, test_ds)\n",
    "  metrics = jax.device_get(metrics)\n",
    "  summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "  return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1, loss: 0.5761, accuracy: 83.79\n",
      " test epoch: 1, loss: 0.33, accuracy: 90.57\n",
      "train epoch: 2, loss: 0.3170, accuracy: 90.97\n",
      " test epoch: 2, loss: 0.29, accuracy: 91.65\n",
      "train epoch: 3, loss: 0.2825, accuracy: 91.98\n",
      " test epoch: 3, loss: 0.28, accuracy: 92.14\n",
      "train epoch: 4, loss: 0.2642, accuracy: 92.43\n",
      " test epoch: 4, loss: 0.26, accuracy: 92.64\n",
      "train epoch: 5, loss: 0.2529, accuracy: 92.76\n",
      " test epoch: 5, loss: 0.26, accuracy: 92.80\n",
      "train epoch: 6, loss: 0.2438, accuracy: 92.99\n",
      " test epoch: 6, loss: 0.25, accuracy: 92.90\n",
      "train epoch: 7, loss: 0.2381, accuracy: 93.10\n",
      " test epoch: 7, loss: 0.25, accuracy: 93.09\n",
      "train epoch: 8, loss: 0.2318, accuracy: 93.35\n",
      " test epoch: 8, loss: 0.24, accuracy: 93.11\n",
      "train epoch: 9, loss: 0.2270, accuracy: 93.48\n",
      " test epoch: 9, loss: 0.25, accuracy: 93.09\n",
      "train epoch: 10, loss: 0.2235, accuracy: 93.48\n",
      " test epoch: 10, loss: 0.24, accuracy: 92.99\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets()\n",
    "rng = jax.random.PRNGKey(1)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "learning_rate = 0.001\n",
    "state = create_train_state(init_rng, learning_rate)\n",
    "del init_rng  # Must not be used anymore.\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  # Use a separate PRNG key to permute image data during shuffling\n",
    "  rng, input_rng = jax.random.split(rng)\n",
    "  # Run an optimization step over a training batch\n",
    "  state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "  # Evaluate on the test set after each training epoch\n",
    "  test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "  print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "      epoch, test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, input_rng = jax.random.split(rng)\n",
    "inters = forward_batch(state, 1000, rng)\n",
    "x1 = np.sign(inters['x1'][0])\n",
    "x2 = np.sign(inters['x2'][0])\n",
    "x = np.concatenate([x1, x2], axis=1)\n",
    "x = (x + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.454 0.971 0.988 0.857 0.677 0.645 0.812 0.764 0.512 0.808 0.953 0.715\n",
      " 0.785 0.808 0.802 0.992]\n",
      "1000\n",
      "[0.13793103 0.         1.         1.         0.31034482 0.44827586\n",
      " 1.         1.         0.06896552 0.6551724  1.         0.10344828\n",
      " 1.         1.         1.         0.82758623]\n",
      "29\n",
      "[0.13793103 0.         1.         1.         0.31034482 0.44827586\n",
      " 1.         1.         0.06896552 0.6551724  1.         0.10344828\n",
      " 1.         1.         1.         0.82758623]\n",
      "29\n",
      "[0.13793103 0.         1.         1.         0.31034482 0.44827586\n",
      " 1.         1.         0.06896552 0.6551724  1.         0.10344828\n",
      " 1.         1.         1.         0.82758623]\n",
      "29\n",
      "[0.13793103 0.         1.         1.         0.31034482 0.44827586\n",
      " 1.         1.         0.06896552 0.6551724  1.         0.10344828\n",
      " 1.         1.         1.         0.82758623]\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(x, axis=0))\n",
    "print(x.shape[0])\n",
    "print(np.mean(x[x[:, 1] == 0], axis=0))\n",
    "print(x[x[:, 1] == 0].shape[0])\n",
    "print(np.mean(x[np.logical_and(x[:, 1] == 0, x[:, 10] == 1)], axis=0))\n",
    "print(x[np.logical_and(x[:, 1] == 0, x[:, 10] == 1)].shape[0])\n",
    "print(np.mean(x[((x[:, 1] == 0) & (x[:, 10] == 1) & (x[:, 3] == 1))], axis=0))\n",
    "print(x[((x[:, 1] == 0) & (x[:, 10] == 1) & (x[:, 3] == 1))].shape[0])\n",
    "print(np.mean(x[((x[:, 1] == 0) & (x[:, 10] == 1) & (x[:, 3] == 1) & (x[:, 7] == 1))], axis=0))\n",
    "print(x[((x[:, 1] == 0) & (x[:, 10] == 1) & (x[:, 3] == 1)) & (x[:, 7] == 1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0.512, (4, 0.5676229508196722, (3, 0.6066350710900474, (7, 0.42168674698795183, 48, 35), (5, 0.5859375, 53, 75)), (5, 0.5487364620938628, (0, 0.496, 63, 62), (0, 0.3223684210526316, (12, 0.6407766990291263, 37, 66), 49))), (0, 0.548828125, (13, 0.4805194805194805, (7, 0.5083333333333333, 59, 61), (14, 0.4774774774774775, 58, 53)), (14, 0.6263345195729537, (5, 0.5619047619047619, 46, 59), (11, 0.6534090909090909, 61, (9, 0.7565217391304347, 28, (5, 0.7126436781609196, 25, 62))))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'// Plinko Tree\\ndigraph {\\n\\t\"\" -> 0\\n\\t0 -> 00\\n\\t00 -> 000\\n\\t0000 [label=\"48 0000\"]\\n\\t000 -> 0000\\n\\t0001 [label=\"35 0001\"]\\n\\t000 -> 0001\\n\\t000 [label=\"Split at 7\\n(n=83, p=0.42) Var 2.94e-03\\nPath P: 8.30e-02 Var: 7.61e-02\"]\\n\\t00 -> 001\\n\\t0010 [label=\"53 0010\"]\\n\\t001 -> 0010\\n\\t0011 [label=\"75 0011\"]\\n\\t001 -> 0011\\n\\t001 [label=\"Split at 5\\n(n=128, p=0.59) Var 1.90e-03\\nPath P: 1.28e-01 Var: 1.12e-01\"]\\n\\t00 [label=\"Split at 3\\n(n=211, p=0.61) Var 1.13e-03\\nPath P: 2.11e-01 Var: 1.66e-01\"]\\n\\t0 -> 01\\n\\t01 -> 010\\n\\t0100 [label=\"63 0100\"]\\n\\t010 -> 0100\\n\\t0101 [label=\"62 0101\"]\\n\\t010 -> 0101\\n\\t010 [label=\"Split at 0\\n(n=125, p=0.50) Var 2.00e-03\\nPath P: 1.25e-01 Var: 1.09e-01\"]\\n\\t01 -> 011\\n\\t011 -> 0110\\n\\t01100 [label=\"37 01100\"]\\n\\t0110 -> 01100\\n\\t01101 [label=\"66 01101\"]\\n\\t0110 -> 01101\\n\\t0110 [label=\"Split at 12\\n(n=103, p=0.64) Var 2.23e-03\\nPath P: 1.03e-01 Var: 9.24e-02\"]\\n\\t0111 [label=\"49 0111\"]\\n\\t011 -> 0111\\n\\t011 [label=\"Split at 0\\n(n=152, p=0.32) Var 1.44e-03\\nPath P: 1.52e-01 Var: 1.29e-01\"]\\n\\t01 [label=\"Split at 5\\n(n=277, p=0.55) Var 8.94e-04\\nPath P: 2.77e-01 Var: 2.00e-01\"]\\n\\t0 [label=\"Split at 4\\n(n=488, p=0.57) Var 5.03e-04\\nPath P: 4.88e-01 Var: 2.50e-01\"]\\n\\t\"\" -> 1\\n\\t1 -> 10\\n\\t10 -> 100\\n\\t1000 [label=\"59 1000\"]\\n\\t100 -> 1000\\n\\t1001 [label=\"61 1001\"]\\n\\t100 -> 1001\\n\\t100 [label=\"Split at 7\\n(n=120, p=0.51) Var 2.08e-03\\nPath P: 1.20e-01 Var: 1.06e-01\"]\\n\\t10 -> 101\\n\\t1010 [label=\"58 1010\"]\\n\\t101 -> 1010\\n\\t1011 [label=\"53 1011\"]\\n\\t101 -> 1011\\n\\t101 [label=\"Split at 14\\n(n=111, p=0.48) Var 2.25e-03\\nPath P: 1.11e-01 Var: 9.87e-02\"]\\n\\t10 [label=\"Split at 13\\n(n=231, p=0.48) Var 1.08e-03\\nPath P: 2.31e-01 Var: 1.78e-01\"]\\n\\t1 -> 11\\n\\t11 -> 110\\n\\t1100 [label=\"46 1100\"]\\n\\t110 -> 1100\\n\\t1101 [label=\"59 1101\"]\\n\\t110 -> 1101\\n\\t110 [label=\"Split at 5\\n(n=105, p=0.56) Var 2.34e-03\\nPath P: 1.05e-01 Var: 9.40e-02\"]\\n\\t11 -> 111\\n\\t1110 [label=\"61 1110\"]\\n\\t111 -> 1110\\n\\t111 -> 1111\\n\\t11110 [label=\"28 11110\"]\\n\\t1111 -> 11110\\n\\t1111 -> 11111\\n\\t111110 [label=\"25 111110\"]\\n\\t11111 -> 111110\\n\\t111111 [label=\"62 111111\"]\\n\\t11111 -> 111111\\n\\t11111 [label=\"Split at 5\\n(n=87, p=0.71) Var 2.35e-03\\nPath P: 8.70e-02 Var: 7.94e-02\"]\\n\\t1111 [label=\"Split at 9\\n(n=115, p=0.76) Var 1.60e-03\\nPath P: 1.15e-01 Var: 1.02e-01\"]\\n\\t111 [label=\"Split at 11\\n(n=176, p=0.65) Var 1.29e-03\\nPath P: 1.76e-01 Var: 1.45e-01\"]\\n\\t11 [label=\"Split at 14\\n(n=281, p=0.63) Var 8.33e-04\\nPath P: 2.81e-01 Var: 2.02e-01\"]\\n\\t1 [label=\"Split at 0\\n(n=512, p=0.55) Var 4.84e-04\\nPath P: 5.12e-01 Var: 2.50e-01\"]\\n\\t\"\" [label=\"Split at 8\\n(n=1000, p=0.51) Var 2.50e-04\\nPath P: 1.00e+00 Var: 0.00e+00\"]\\n}\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def id3(x):\n",
    "    if x.shape[0] < 80:\n",
    "        return x.shape[0]\n",
    "    marginals = np.mean(x, axis=0)\n",
    "    split_dim = np.argmin(np.abs(marginals - 0.5))\n",
    "    p = x[x[:, split_dim] == 1].shape[0] / x.shape[0]\n",
    "    return split_dim, p, id3(x[x[:, split_dim] == 0]), id3(x[x[:, split_dim] == 1])\n",
    "\n",
    "def viz(t):\n",
    "    dot = graphviz.Digraph(comment='Plinko Tree')\n",
    "    def parse_tuple(t, bs='', ps=[]):\n",
    "        if len(bs) > 0:\n",
    "            dot.edge(bs[:-1], bs)\n",
    "        dim, p, left, right = t\n",
    "        if isinstance(left, tuple):\n",
    "            l_number = parse_tuple(left, bs + '0', ps=ps+[1-p])\n",
    "        else:\n",
    "            dot.node(bs + '0', '{} {}'.format(left, bs + '0'))\n",
    "            dot.edge(bs, bs + '0')\n",
    "            l_number = left\n",
    "        if isinstance(right, tuple):\n",
    "            r_number = parse_tuple(right, bs + '1', ps=ps+[p])\n",
    "        else:\n",
    "            dot.node(bs + '1', '{} {}'.format(right, bs + '1'))\n",
    "            dot.edge(bs, bs + '1')\n",
    "            r_number = right\n",
    "        est_n = (l_number + r_number)\n",
    "        est_var = (p * (1 - p)) / est_n\n",
    "        path_prob = np.prod(ps)\n",
    "        path_var = np.prod(ps) - np.prod(np.square(ps))\n",
    "        dot.node(bs, \"Split at {}\\n(n={}, p={:.2f}) Var {:.2e}\\nPath P: {:.2e} Var: {:.2e}\".format(dim, est_n, p, est_var, path_prob, path_var))\n",
    "        return l_number + r_number\n",
    "    parse_tuple(t)\n",
    "    return dot\n",
    "\n",
    "t = id3(x)\n",
    "print(t)\n",
    "dot = viz(t)\n",
    "dot.render('doctest-output/round-table.gv', view=True)\n",
    "dot.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b65145852783e9c7205dc9a03bc37915289fb7284de0b0350e5dcaa4bb0c2e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
